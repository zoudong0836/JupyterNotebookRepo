{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#cv2.absdiff\" data-toc-modified-id=\"cv2.absdiff-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>cv2.absdiff</a></span></li><li><span><a href=\"#cv2.inRange\" data-toc-modified-id=\"cv2.inRange-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span><a href=\"https://blog.csdn.net/hjxu2016/article/details/77834599\" target=\"_blank\">cv2.inRange</a></a></span></li><li><span><a href=\"#cv2.calcHist\" data-toc-modified-id=\"cv2.calcHist-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><a href=\"https://blog.csdn.net/sunny2038/article/details/9097989\" target=\"_blank\">cv2.calcHist</a></a></span></li><li><span><a href=\"#cv2.normalize\" data-toc-modified-id=\"cv2.normalize-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>cv2.normalize</a></span></li><li><span><a href=\"#cv2.getStructuringElement\" data-toc-modified-id=\"cv2.getStructuringElement-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>cv2.getStructuringElement</a></span></li><li><span><a href=\"#cv2.distanceTransform\" data-toc-modified-id=\"cv2.distanceTransform-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>cv2.distanceTransform</a></span></li><li><span><a href=\"#cv2.pyrMeanShiftFiltering\" data-toc-modified-id=\"cv2.pyrMeanShiftFiltering-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>cv2.pyrMeanShiftFiltering</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.absdiff\n",
    "\n",
    "> 获取差分图; 就是将两幅图像作差，返回的结果代表他们的差异之处\n",
    "```python\n",
    "cv2.absdiff(src1, src2, dst=None)\n",
    "```\n",
    ">> 两个图片相减用的是灰度图，类型是uint8(在OpenCV单通道使用的数据类型是 uint8)；两个uint8的数相减得不到负数,会得到差的补码  \n",
    "\n",
    "> 对于一个固定的场景（背景），感兴趣的是在场景中运动的物体（前景）。如果摄像机是固定的，那么可以认为场景（背景）大多数情况下是不变的，而只有前景（被跟踪的目标）会运动，这样就可以建立背景模型。通过比较当前帧和背景模型，就能轻松地跟踪目标运动情况了。这里，最容易想到的比较方式就是当前帧减去背景模型了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [cv2.inRange](https://blog.csdn.net/hjxu2016/article/details/77834599)\n",
    "\n",
    "> 该函数可实现二值化功能（这点类似threshold()函数），更关键的是可以同时针对多通道进行操作\n",
    "```python\n",
    "cv2.inRange(src, lowerb, upperb, dst=None)\n",
    "```\n",
    "> 参数说明：\n",
    "```python\n",
    "* src: 指定原图, 通常是 HSV 图像\n",
    "* lowerb: 指的是图像中低于这个lowerb的值，图像值变为0\n",
    "* upperb: 指的是图像中高于这个upperb的值, 图像值变为0\n",
    "* 在 lowerb ~ upperb 之间的值变为 255\n",
    "```\n",
    "\n",
    ">> 针对单通道图像  \n",
    "* 假设lowerb=[0]，upperb=[128]，那么，对每个数在0-128之间为255，否则为0，，这样就生成了一幅二值化的输出图像。\n",
    "\n",
    ">> 针对多通道图像\n",
    "* 假设lower=[0，0, 0]，upper=[128, 128, 128]，那么，对每一行，对任意一个数，如果在范围内，则255，否则0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [cv2.calcHist](https://blog.csdn.net/sunny2038/article/details/9097989)\n",
    "> calcHist函数用来计算图像的彩色直方图。所谓的彩色直方图是指图像的颜色分布，它的 `x` 轴是色彩值，`y` 轴是相应色彩值的像素数量  \n",
    "在OpenCV中，彩色直方图每列的取值范围在 0~180 之间(OpenCV使用的 `H` 值范围在 0~180 之间)\n",
    "```python\n",
    "cv2.calcHist(images, channels, mask, histSize, ranges, hist=None, accumulate=None)\n",
    "```\n",
    "> 参数说明：\n",
    "```python\n",
    "* images: 原图像(图像格式为uint8或float32), 当传入函数时应该用中括号[]括起来\n",
    "* channels: 如果输入图像是灰度图, 它的值就是[0]; 如果是彩色图像的话, 传入的参数可以是 [0], [1], [2] 它们分别对应着通道 B, G, R (同样需要用中括号括起来)\n",
    "* mask: 掩模图像。要统计整幅图像的直方图就把它设为 None。但是如果想统计图像某一部分的直方图的话，就需要制作一个掩模图像，并使用它\n",
    "* histSize:  该参数是每个维度下直方图数组的大小。也应该用中括号括起来，例如： [256]\n",
    "* ranges: 要统计的灰度值范围，一般来说为 [0， 256]，也就是说所有的灰度值\n",
    "```\n",
    "> 示例: 一副图中同时绘制三个通道的直方图\n",
    "```python\n",
    "import cv2  \n",
    "import numpy as np  \n",
    "img = cv2.imread('D:/lena.jpg')  \n",
    "h = np.zeros((256,256,3))           # 创建用于绘制直方图的全0图像    \n",
    "bins = np.arange(256).reshape(256,1)     # 直方图中各bin的顶点位置  \n",
    "color = [ (255,0,0),(0,255,0),(0,0,255) ]   # BGR三种颜色  \n",
    "for ch, col in enumerate(color):  \n",
    "    originHist = cv2.calcHist([img],[ch],None,[256],[0,256])  \n",
    "    cv2.normalize(originHist,originHist,0,255*0.9,cv2.NORM_MINMAX)  \n",
    "    hist=np.int32(np.around(originHist))  \n",
    "    pts = np.column_stack((bins,hist))  \n",
    "    cv2.polylines(h,[pts],False,col)  \n",
    "h=np.flipud(h)  \n",
    "cv2.imshow('colorhist',h)  \n",
    "cv2.waitKey(0) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.normalize\n",
    "> 归一化就是要把需要处理的数据经过处理后（通过某种算法）限制在所需要的一定范围内；归一化的目的，是使得没有可比性的数据变得具有可比性，同时又保持相比较的两个数据之间的相对关系，如大小关系；或是为了作图，原来很难在一张图上作出来，归一化后就可以很方便的给出图上的相对位置等\n",
    "```python\n",
    "cv2.normalize(src, dst, alpha=None, beta=None, norm_type=None, dtype=None, mask=None)\n",
    "```\n",
    "> 参数说明：\n",
    "```python\n",
    "* src: 输入数组\n",
    "* dst: 输出数组\n",
    "* alpha: range normalization 模式的最小值 (归一化后最小值)\n",
    "* beta: range normalization 模式的最大值 (归一化后最大值)\n",
    "* norm_type: 归一化的类型:\n",
    "  1. NORM_MINMAX:数组的数值被平移或缩放到一个指定的范围，线性归一化，一般较常用\n",
    "  2. NORM_INF\n",
    "  3. NORM_L1: 归一化数组的L1-范数(绝对值的和)\n",
    "  4. NORM_L2: 归一化数组的(欧几里德)L2-范数\n",
    "* dtype: 为负数时，输出数组的type与输入数组的type相同\n",
    "* mask: 操作掩膜，用于指示函数是否仅仅对指定的元素进行操作\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.getStructuringElement\n",
    "> 返回指定形状和尺寸的结构元素\n",
    "```python\n",
    "getStructuringElement(shape, ksize, anchor=None)\n",
    "```\n",
    "> 参数说明：\n",
    "```python\n",
    "* shape: 指定内核的形状, 有三种选择:\n",
    "    * MORPH_RECT: 矩形\n",
    "    * MORPH_CROSS:  交叉形(十字形)\n",
    "    * MORPH_ELLIPSE:  椭圆形\n",
    "* ksize: 指定内核的尺寸\n",
    "* anchor: 指定锚点的位置\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.distanceTransform\n",
    "> 计算从每个二进制图像像素到最近的零像素的近似或精确距离\n",
    "```python\n",
    "cv2.distanceTransform(src, distanceType, maskSize[, dst]) → dst\n",
    "```\n",
    "> 参数说明:\n",
    "```python\n",
    "* src - 8位，单通道（二进制）源图像。\n",
    "* distanceType - 距离类型。它可以是 ，或 。CV_DIST_L1, CV_DIST_L2CV_DIST_C\n",
    "* maskSize - 距离变换掩码的大小。它可以是3, 5\n",
    "```\n",
    "> [原理介绍：](https://blog.csdn.net/liubing8609/article/details/78483667)   \n",
    "可以通过`距离变换`来实现目标细化, 骨架提取, 形状插值及匹配、粘连物体的分离等。距离变换是针对二值图像的一种变换，是计算并标识空间点(对目标点)距离的过程，它最终把二值图像变换为灰度图像(其中每个像素的灰度值等于它到最近目标点的距离)。在二维空间中，一幅二值图像可以任务仅仅包含目标和背景两种像素，目标的像素值为1，背景的像素值为0；距离变换的结果不是另一幅二值图像，而是一幅灰度图像，即距离图像，图像中每个像素的灰度值为该像素与距其最近的背景像素间的距离。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.pyrMeanShiftFiltering\n",
    "> 进行图像在色彩层面的平滑滤波，它可以中和色彩分布相近的颜色，平滑色彩细节，侵蚀掉面积较小的颜色区域\n",
    "```python\n",
    "cv2.pyrMeanShiftFiltering(src, sp, sr[, dst[, maxLevel[, termcrit]]]) → dst\n",
    "```\n",
    "> 参数说明：\n",
    "```python\n",
    "* src: 输入图像，8位，三通道的彩色图像，并不要求必须是RGB格式，HSV、YUV等Opencv中的彩色图像格式均可\n",
    "* dst: 输出图像，跟输入src有同样的大小和数据格式\n",
    "* sp: 定义的漂移物理空间半径大小\n",
    "* sr: 定义的漂移色彩空间半径大小\n",
    "* maxLevel: 定义金字塔的最大层数；\n",
    "* termcrit: 定义的漂移迭代终止条件，可以设置为迭代次数满足终止，迭代目标与中心点偏差满足终止，或者两者的结合\n",
    "```\n",
    "> [执行过程：](https://www.cnblogs.com/jesse123/p/7550289.html)\n",
    "1. `迭代空间构建：`\n",
    "以输入图像上src上任一点P0为圆心，建立物理空间上半径为sp，色彩空间上半径为sr的球形空间，物理空间上坐标2个—x、y，色彩空间上坐标3个—R、G、B（或HSV），构成一个5维的空间球体。【其实就是升维的思想】\n",
    "其中物理空间的范围x和y是图像的长和宽，色彩空间的范围R、G、B分别是0~255。\n",
    "2. `求取迭代空间的向量并移动迭代空间球体后重新计算向量，直至收敛：`在1中构建的球形空间中，求得所有点相对于中心点的色彩向量之和后，移动迭代空间的中心点到该向量的终点，并再次计算该球形空间中所有点的向量之和，如此迭代，直到在最后一个空间球体中所求得的向量和的终点就是该空间球体的中心点Pn，迭代结束。\n",
    "3. 更新输出图像dst上对应的初始原点P0的色彩值为本轮迭代的终点Pn的色彩值，如此完成一个点的色彩均值漂移。\n",
    "4. 对输入图像src上其他点，依次执行步骤1,、2、3，遍历完所有点位后，整个均值偏移色彩滤波完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

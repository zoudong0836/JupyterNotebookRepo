{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [图像阈值](http://ex2tron.wang/2017/12/07/Python-OpenCV%E6%95%99%E7%A8%8B6%EF%BC%9A%E9%98%88%E5%80%BC%E5%88%86%E5%89%B2/)\n",
    "\n",
    "### 简单阈值\n",
    "> 整幅图像采用同一个数作为阈值（全局阈值）。像素值高于阈值时，给这个像素赋予一个新值（可能是白色），否则我们给它赋予另外一种颜色（也许是黑色）。这个函数就是 cv2.threshhold()。\n",
    "\n",
    ">>函数原型:  \n",
    "```\n",
    "threshold(src, thresh, maxval, type[, dst]) -> retval, dst\n",
    "```\n",
    ">* 第一个参数就是原图像，原图像应该是灰度图  \n",
    ">* 第二个参数就是用来对像素值进行分类的阈值  \n",
    ">* 第三个参数就是当像素值高于（有时是小于）阈值时应该被赋予的新的像素值   \n",
    ">* OpenCV提供了多种不同的阈值方法，这是有第四个参数来决定的。这些方法包括： \n",
    "\n",
    "\n",
    ">>阈值类型一般分为五种： \n",
    "```\n",
    "cv2.THRESH_BINARY —— 大于阈值的部分像素值变为最大值，其他变为0   \n",
    "cv2.THRESH_BINARY_INV —— 大于阈值的部分变为0，其他部分变为最大值   \n",
    "cv2.THRESH_TRUNC —— 大于阈值的部分变为阈值，其余部分不变   \n",
    "cv2.THRESH_TOZERO —— 大于阈值的部分不变，其余部分变为0   \n",
    "cv2.THRESH_TOZERO_INV —— 大于阈值的部分变为0，其余部分不变  \n",
    "```\n",
    "\n",
    "### 自适应阈值\n",
    "> 当同一幅图像上的不同部分的具有不同亮度时，这种情况下需要采用自适应阈值。此时的阈值是根据图像上的每一个小区域计算与其对应的阈值。因此在同一幅图像上的不同区域采用的是不同的阈值，从而能在亮度不同的情况下得到更好的结果\n",
    "\n",
    "\n",
    ">>函数原型:\n",
    "```\n",
    "adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) -> dst\n",
    "```\n",
    ">* 参数1：要处理的原图  \n",
    ">* 参数2：最大阈值，一般为255  \n",
    ">* 参数3：小区域阈值的计算方式  \n",
    "     ADAPTIVE_THRESH_MEAN_C：小区域内取均值    \n",
    "     ADAPTIVE_THRESH_GAUSSIAN_C：小区域内加权求和，权重是个高斯核\n",
    ">* 参数4：阈值方式（跟前面讲的那5种相同）\n",
    ">* 参数5：邻域的面积，如11就是11x11的小块\n",
    ">* 参数6：一个常数，最终阈值等于小区域计算出的阈值再减去此值\n",
    "\n",
    "### [Otsu's 二值化](http://ex2tron.wang/2017/12/08/Python-OpenCV%E6%95%99%E7%A8%8B%E7%95%AA%E5%A4%96%E7%AF%874%EF%BC%9AOtsu%E9%98%88%E5%80%BC%E6%B3%95/)\n",
    "> 如果是一幅双峰图像（双峰图像是指图像直方图中存在两个峰）应该在两个峰之间的峰谷选一个值作为阈值。这就是 Otsu 二值化要做的。简单来说就是对一幅双峰图像自动根据其直方图计算出一个阈值。（对于非双峰图像，这种方法得到的结果可能会不理想）\n",
    "\n",
    "> 用到到的函数还是 cv2.threshold()，但是需要多传入一个参数（flag）： cv2.THRESH_OTSU。这时要把阈值设为 0。然后算法会找到最优阈值，这个最优阈值就是返回值 retVal。如果不使用 Otsu 二值化，返回的retVal 值与设定的阈值相等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [滤波和模糊](http://ex2tron.wang/2017/12/15/Python-OpenCV%E6%95%99%E7%A8%8B10%EF%BC%9A%E5%B9%B3%E6%BB%91%E5%9B%BE%E5%83%8F/)\n",
    "\n",
    "> 过滤是信号和图像处理中基本的任务。其目的是根据应用环境的不同，选择性的提取图像中某些认为是重要的信息。过滤可以移除图像中的噪音、提取感兴趣的可视特征、允许图像重采样等等。频域分析将图像分成从低频到高频的不同部分。低频对应图像强度变化小的区域，而高频是图像强度变化非常大的区域。在频率分析领域的框架中，滤波器是一个用来增强图像中某个波段或频率并阻塞（或降低）其他频率波段的操作。低通滤波器是消除图像中高频部分，但保留低频部分。高通滤波器消除低频部分；模糊操作就是过滤掉图像中的一些特殊噪音\n",
    "* 低通滤波器（lowpass）是模糊，减弱或阻隔高频信号，保留低频信号    \n",
    "* 高通滤波器（highpass）是锐化，减弱或阻隔低频信号，保留高频信号  \n",
    "\n",
    ">> 低通滤波器就是允许低频信号通过，在图像中边缘和噪点都相当于高频部分，所以低通滤波器用于去除噪点、平滑和模糊图像。\n",
    "高通滤波器则反之，用来增强图像边缘，进行锐化处理\n",
    "\n",
    ">> 常见噪声有椒盐噪声和高斯噪声，椒盐噪声可以理解为斑点，随机出现在图像中的黑点或白点；高斯噪声可以理解为拍摄图片时由于光照等原因造成的噪声；这样解释并不准确，只要能简单分辨即可\n",
    "\n",
    "> 使用低通滤波器可以达到图像模糊的目的。这对与去除噪音很有帮助。其实就是去除图像中的高频成分（比如：噪音，边界）。所以边界也会被模糊一点。（当然，也有一些模糊技术不会模糊掉边界）。 OpenCV 提供了四种模糊技术\n",
    "\n",
    "### 均值滤波\n",
    "> 均值滤波是一种最简单的滤波处理，它取的是卷积核区域内元素的均值，用cv2.blur()实现：\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "blur(src, ksize[, dst[, anchor[, borderType]]]) -> dst\n",
    "```\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "img = cv2.imread('img/lena.jpg')\n",
    "img = cv2.blur(img, (3, 3))   # 使用 3×3的卷积核\n",
    "```\n",
    "\n",
    "### 方框滤波\n",
    "> 方框滤波跟均值滤波很像，用cv2.boxFilter()函数实现，事实上，当可选参数normalize为True的时候，方框滤波就是均值滤波；normalize为False的时候，相当于求区域内的像素和\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "boxFilter(src, ddepth, ksize[, dst[, anchor[, normalize[, borderType]]]]) -> dst\n",
    "```\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "* 前面的均值滤波也可以用方框滤波实现：normalize=True\n",
    "blur = cv2.boxFilter(img, -1, (3, 3), normalize=True)\n",
    "```\n",
    "\n",
    "### [高斯滤波](http://www.ruanyifeng.com/blog/2012/11/gaussian_blur.html)\n",
    "> 高斯滤波器是一种线性滤波器，能够有效的抑制噪声，平滑图像。把卷积核换成高斯核（简单来说，方框不变，将原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包。原来的求平均数现在变成求加权平均数，全就是方框里的值）。实现的函数是 cv2.GaussianBlur()。需要指定高斯核的宽和高（必须是奇数）。以及高斯函数沿 X， Y 方向的标准差。如果只指定了 X 方向的的标准差， Y 方向也会取相同值。如果两个标准差都是 0，那么函数会根据核函数的大小自己计算。高斯滤波可以有效的从图像中去除高斯噪音\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "img = cv2.GaussianBlur(img, (5, 5), 1) # 使用 5×5的高斯核\n",
    "```\n",
    "\n",
    "> 注：高斯滤波相比均值滤波效率要慢，但可以有效消除高斯噪声，能保留更多的图像细节，所以经常被称为最有用的滤波器。\n",
    "\n",
    "### 中值滤波\n",
    "> 中值又叫中位数，是所有值排序后取中间的值。中值滤波就是用区域内的中值来代替本像素值，所以那种孤立的斑点，如0或255很容易消除掉，适用于去除椒盐噪声和斑点噪声。中值是一种非线性操作，效率相比前面几种线性滤波要慢。\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "medianBlur(src, ksize[, dst]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "img = cv2.medianBlur(img, 5)   \n",
    "```\n",
    "\n",
    "### 双边滤波\n",
    "> 已知道高斯滤波器是求中心点邻近区域像素的高斯加权平均值。这种高斯滤波器只考虑像素之间的空间关系，而不会考虑像素值之间的关系（像素的相似度）。所以这种方法不会考虑一个像素是否位于边界，因此边界也会别模糊掉。\n",
    "函数 cv2.bilateralFilter() 能在保持边界清晰的情况下有效的去除噪音，但是这种操作与其他滤波器相比会比较慢；双边滤波在同时使用`*空间高斯权重*`和`*灰度值相似性高斯权重*`；空间高斯函数确保只有邻近区域的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以这种方法会确保边界不会被模糊掉，因为边界处的灰度值变化比较大\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "img = cv2.bilateralFilter(img, 9, 75, 75)   \n",
    "```\n",
    "\n",
    "### 小结\n",
    "* 在不知道用什么滤波器好的时候，优先高斯滤波 cv2.GaussianBlur()，然后均值滤波 cv2.blur()\n",
    "* 斑点和椒盐噪声优先使用中值滤波 cv2.medianBlur()\n",
    "* 要去除噪点的同时尽可能保留更多的边缘信息，使用双边滤波 cv2.bilateralFilter()\n",
    "* 线性滤波方式：均值滤波、方框滤波、高斯滤波（速度相对快）\n",
    "* 非线性滤波方式：中值滤波、双边滤波（速度相对慢）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 边缘检测的步骤\n",
    "> * 滤波: 消除噪音  \n",
    "边缘检测的算法主要是基于图像强度的一阶和二阶导数，但导数通常对噪声很敏感，因此必须采用滤波器来改善与噪声有关的边缘检测器的性能。常见的滤波方法主要有`高斯滤波`，即采用离散化的高斯函数产生一组归一化的高斯核，然后基于高斯核函数对图像灰度矩阵的每一点进行加权求和\n",
    "\n",
    "> * 增强: 使边界轮廓更加明显  \n",
    "增强边缘的基础是确定图像各点邻域强度的变化值。增强算法可以将图像灰度点邻域强度值有显著变化的点凸显出来。在具体编程实现时，可通过计算`梯度幅值`来确定\n",
    "\n",
    "> * 检测: 选出边缘点  \n",
    "经过增强的图像，往往邻域中有很多点的梯度值比较大，而在特定的应用中，这些点并不是我们要找的边缘点，所以应该采用某种方法来对这些点进行取舍。实际工程中，常用的方法是通过`阈值化`方法来检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [图像梯度](http://ex2tron.wang/2017/12/18/Python-OpenCV教程番外篇8：图像梯度/)\n",
    "\n",
    "> 把图片想象成连续函数，因为边缘部分的像素值是与旁边像素明显有区别的，所以对图片局部求极值，就可以得到整幅图片的边缘信息了。不过图片是二维的离散函数，导数就变成了差分，这个差分就称为[图像的梯度](https://blog.csdn.net/saltriver/article/details/78987096)\n",
    "\n",
    "> 当用均值滤波器降低图像噪声的时候，会带来图像模糊的副作用。那么，清晰图像和模糊图像之间的差别在哪里呢？从逻辑上考虑，图像模糊是因为图像中物体的轮廓不明显，轮廓边缘灰度变化不强烈，层次感不强造成的，那么反过来考虑，轮廓边缘灰度变化明显些，层次感强些的图像就更清晰些。\n",
    "那么，这种灰度变化明显不明显怎样去定义呢。知道微分就是求函数的变化率，即导数（梯度），那么对于图像来说，可以用微分来表示图像灰度的变化率；因为图像是一个离散的二维函数f(x, y)，其微分就是偏微分\n",
    "\n",
    "> 如果相邻像素灰度值有变化，那么梯度就有值，如果相邻像素灰度值没有变化，那么梯度就为0。如果把梯度值与对应的像素相加，那么灰度值没有变化的，像素值不变，而有梯度值的，灰度值变大了；对比度显然增强了，尤其是图像中物体的轮廓和边缘，与背景大大加强了区别，这就是用梯度来增强图像的原理\n",
    "\n",
    "### Soble算子\n",
    "\n",
    "> Sobel 算子是`高斯平滑`与`微分操作`的结合体，所以它的抗噪声能力很好。可以设定求导的方向（xorder 或 yorder）。还可以设定使用的卷积核的大小（ksize）。如果 ksize=-1，会使用 3x3 的 Scharr 滤波器，它的的效果要比 3x3 的 Sobel 滤波器好（而且速度相同，所以在使用 3x3 滤波器时应该尽量使用 Scharr 滤波器）\n",
    "\n",
    "> * sobel算子在水平和垂直方向两个方向上作边缘检测运算\n",
    "> * sobel算子也同上一篇博文中提到的边缘检测算法一样，在水平和垂直方向两个方向上作边缘检测运算\n",
    "> * sobel算对噪声具有平滑作用，提供较为精确的边缘方向信息，边缘定位精度不够高。当对精度要求不是很高时，是一种较为常用的边缘检测方法\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "sobelX = cv2.Sobel(image,cv2.CV_64F,1,0)          # x方向的梯度\n",
    "sobelY = cv2.Sobel(image,cv2.CV_64F,0,1)          # y方向的梯度\n",
    "sobelX = np.uint8(np.absolute(sobelX))            # x方向梯度的绝对值\n",
    "sobelY = np.uint8(np.absolute(sobelY))            # y方向梯度的绝对值\n",
    "sobelCombined = cv2.bitwise_or(sobelX,sobelY)     # 合并\n",
    "```\n",
    "\n",
    ">> [示例](https://blog.csdn.net/GarfieldEr007/article/details/51326218):\n",
    "```python\n",
    "import cv2  \n",
    "import numpy as np    \n",
    "img = cv2.imread(\"D:/lion.jpg\", 0)  \n",
    "x = cv2.Sobel(img,cv2.CV_16S,1,0)  \n",
    "y = cv2.Sobel(img,cv2.CV_16S,0,1)  \n",
    "absX = cv2.convertScaleAbs(x)                     # 转回uint8  \n",
    "absY = cv2.convertScaleAbs(y)  \n",
    "dst = cv2.addWeighted(absX,0.5,absY,0.5,0)  \n",
    "cv2.imshow(\"absX\", absX)  \n",
    "cv2.imshow(\"absY\", absY)  \n",
    "cv2.imshow(\"Result\", dst)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  \n",
    "```\n",
    "\n",
    "> 解释:\n",
    "\n",
    ">> 在Sobel函数的第二个参数这里使用了`cv2.CV_16S`。因为OpenCV文档中对Sobel算子的介绍中有这么一句：“in the case of 8-bit input images it will result in truncated derivatives”。即Sobel函数求完导数后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，所以Sobel建立的图像位数不够，会有截断。因此要使用16位有符号的数据类型，即cv2.CV_16S。\n",
    "\n",
    ">> 在经过处理后，别忘了用`cv2.convertScaleAbs()`函数将其转回原来的uint8形式。否则将无法显示图像，而只是一副灰色的窗口。convertScaleAbs()的原型为：convertScaleAbs(src[, dst[, alpha[, beta]]]) -> dst； 其中可选参数alpha是伸缩系数，beta是加到结果上的一个值。结果返回uint8类型的图片\n",
    "\n",
    ">> 由于Sobel算子是在两个方向计算的，最后还需要用`cv2.addWeighted`函数将其组合起来。其函数原型为：addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) -> dst；其中alpha是第一幅图片中元素的权重，beta是第二个的权重，gamma是加到最后结果上的一个值\n",
    "\n",
    "\n",
    "### Scharr算子\n",
    "\n",
    "> Scharr函数只是比Sobel函数少了个ksize的参数，原因是它的ksize是定值3\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "Scharr(src, ddepth, dx, dy[, dst[, scale[, delta[, borderType]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "grad_x = cv.Scharr(image, cv.CV_32F, 1, 0)   #对x求一阶导\n",
    "grad_y = cv.Scharr(image, cv.CV_32F, 0, 1)   #对y求一阶导\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### [Laplacian算子](https://blog.csdn.net/sunny2038/article/details/9188441)\n",
    "\n",
    "> 图像中的边缘区域，像素值会发生“跳跃”，对这些像素求导，在其一阶导数在边缘位置为极值，这就是Sobel算子使用的原理——极值处就是边缘。如果对像素值求二阶导数，会发现边缘处的导数值为0；Laplace函数实现的方法是先用Sobel 算子计算二阶x和y导数，再求和\n",
    "\n",
    "> 边缘检测本身属于锐化操作，对噪点比较敏感，所以需要进行平滑处理，通常对图像先进行低通滤波（高斯模糊处理），再使用 Laplacian算子\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst\n",
    "```\n",
    ">> * 第一个参数是需要处理的图像\n",
    ">> * 第二个参数是图像的深度，-1表示采用的是与原图像相同的深度。目标图像的深度必须大于等于原图像的深度\n",
    ">> * 可选参数：ksize是算子的大小，必须为1、3、5、7。默认为1\n",
    ">> * 可选参数：scale是缩放导数的比例常数，默认情况下没有伸缩系数\n",
    ">> * 可选参数：delta是一个可选的增量，将会加到最终的dst中，同样，默认情况下没有额外的值加到dst中\n",
    ">> * 可选参数：borderType是判断图像边界的模式。这个参数默认值为cv2.BORDER_DEFAULT\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "gray_lap = cv2.Laplacian(img, cv2.CV_16S, ksize = 3)  \n",
    "dst = cv2.convertScaleAbs(gray_lap)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [形态学转换](http://ex2tron.wang/2017/12/19/Python-OpenCV教程12：腐蚀与膨胀/)\n",
    "\n",
    "> 形态学操作是根据图像形状进行的简单操作（改变物体的形状）。一般情况下对二值化图像进行的操作。需要输入两个参数，一个是原始图像，第二个被称为结构化元素或核，它是用来决定操作的性质的。  \n",
    "两个基本的形态学操作是腐蚀和膨胀。他们的变体构成了开运算，闭运算，梯度等  \n",
    "形态学操作一般作用于二值化图，来连接相邻的元素或分离成独立的元素。腐蚀和膨胀是针对图片中的白色部分！  \n",
    "\n",
    "### 腐蚀\n",
    "> 就像土壤侵蚀一样，这个操作会把前景物体的边界腐蚀掉（但是前景仍然是白色）。卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是 1，那么中心元素就保持原来的像素值，否则就变为零。  \n",
    "根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为 0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪声很有用，也可以用来断开两个连在一块的物体等  \n",
    "总结： 腐蚀的效果是把图片”变瘦”，其原理是在原图的小区域内取局部最小值。因为是二值化图，只有0和255，所以小区域内有一个是0该像素点就为0\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "erode(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "erosion = cv2.erode(img, kernel, iterations=1)\n",
    "```\n",
    ">> 补充：  \n",
    ">>>这个核 kernel 也叫结构元素，因为形态学操作其实也是应用卷积来实现的。结构元素可以是矩形/椭圆/十字形，可以用cv2.getStructuringElement()来生成不同形状的结构元素，比如：\n",
    "```python\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))     # 矩形结构\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # 椭圆结构\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5))    # 十字形结构\n",
    "```\n",
    "\n",
    "\n",
    "### 膨胀\n",
    "> 与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是 1，中心元素的像素值就是 1。所以这个操作会增加图像中的白色区域（前景）。一般在去\n",
    "噪声时先用腐蚀再用膨胀。因为腐蚀在去掉白噪声的同时，也会使前景对象变小。所以需要再对他进行膨胀。这时噪声已经被去除了，不会再回来了，但是前景还在并会增加。膨胀也可以用来连接两个分开的物体  \n",
    "总结：膨胀与腐蚀相反，取的是局部最大值，效果是把图片”变胖”\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "dilate(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilation = cv2.dilate(img, kernel, iterations = 1)\n",
    "```\n",
    "\n",
    "### 开运算\n",
    "> 先腐蚀后膨胀叫开运算（因为先腐蚀会分开物体），其作用是：分离物体，消除小区域\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "```\n",
    "\n",
    "### 闭运算\n",
    "> 先膨胀再腐蚀。它经常被用来填充前景物体中的小洞，或者前景物体上的小黑点\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "```\n",
    "\n",
    "### 形态学梯度\n",
    "> 就是一幅图像膨胀与腐蚀的差别。膨胀图减去腐蚀图，dilation - erosion，这样会得到物体的轮廓\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "```\n",
    "\n",
    "### 顶帽\n",
    "> 原图减去开运算（先腐蚀再膨胀）后的图：src - opening\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "```\n",
    "\n",
    "### 黑帽\n",
    "> 闭运算（先膨胀再腐蚀）后的图减去原图：closing - src\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "```\n",
    "\n",
    "### 小结\n",
    "* 形态学操作就是改变物体的形状，如腐蚀使物体”变瘦”，膨胀使物体”变胖”\n",
    "* 先腐蚀后膨胀会分离物体，所以叫开运算，常用来去除小区域物体\n",
    "* 先膨胀后腐蚀会消除物体内的小洞，所以叫闭运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

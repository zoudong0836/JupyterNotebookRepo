{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#图像阈值\" data-toc-modified-id=\"图像阈值-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><a href=\"http://ex2tron.wang/2017/12/07/Python-OpenCV%E6%95%99%E7%A8%8B6%EF%BC%9A%E9%98%88%E5%80%BC%E5%88%86%E5%89%B2/\" target=\"_blank\">图像阈值</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#简单阈值\" data-toc-modified-id=\"简单阈值-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>简单阈值</a></span></li><li><span><a href=\"#自适应阈值\" data-toc-modified-id=\"自适应阈值-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>自适应阈值</a></span></li><li><span><a href=\"#Otsu's-二值化\" data-toc-modified-id=\"Otsu's-二值化-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><a href=\"http://ex2tron.wang/2017/12/08/Python-OpenCV%E6%95%99%E7%A8%8B%E7%95%AA%E5%A4%96%E7%AF%874%EF%BC%9AOtsu%E9%98%88%E5%80%BC%E6%B3%95/\" target=\"_blank\">Otsu's 二值化</a></a></span></li></ul></li><li><span><a href=\"#滤波和模糊\" data-toc-modified-id=\"滤波和模糊-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span><a href=\"http://ex2tron.wang/2017/12/15/Python-OpenCV%E6%95%99%E7%A8%8B10%EF%BC%9A%E5%B9%B3%E6%BB%91%E5%9B%BE%E5%83%8F/\" target=\"_blank\">滤波和模糊</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#均值滤波\" data-toc-modified-id=\"均值滤波-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>均值滤波</a></span></li><li><span><a href=\"#方框滤波\" data-toc-modified-id=\"方框滤波-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>方框滤波</a></span></li><li><span><a href=\"#高斯滤波\" data-toc-modified-id=\"高斯滤波-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span><a href=\"http://www.ruanyifeng.com/blog/2012/11/gaussian_blur.html\" target=\"_blank\">高斯滤波</a></a></span></li><li><span><a href=\"#中值滤波\" data-toc-modified-id=\"中值滤波-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>中值滤波</a></span></li><li><span><a href=\"#双边滤波\" data-toc-modified-id=\"双边滤波-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>双边滤波</a></span></li><li><span><a href=\"#小结\" data-toc-modified-id=\"小结-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>小结</a></span></li></ul></li><li><span><a href=\"#边缘检测的步骤\" data-toc-modified-id=\"边缘检测的步骤-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>边缘检测的步骤</a></span></li><li><span><a href=\"#图像梯度\" data-toc-modified-id=\"图像梯度-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span><a href=\"http://ex2tron.wang/2017/12/18/Python-OpenCV教程番外篇8：图像梯度/\" target=\"_blank\">图像梯度</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Soble算子\" data-toc-modified-id=\"Soble算子-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Soble算子</a></span></li><li><span><a href=\"#Scharr算子\" data-toc-modified-id=\"Scharr算子-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Scharr算子</a></span></li><li><span><a href=\"#Laplacian算子\" data-toc-modified-id=\"Laplacian算子-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span><a href=\"https://blog.csdn.net/sunny2038/article/details/9188441\" target=\"_blank\">Laplacian算子</a></a></span></li></ul></li><li><span><a href=\"#形态学转换\" data-toc-modified-id=\"形态学转换-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span><a href=\"http://ex2tron.wang/2017/12/19/Python-OpenCV教程12：腐蚀与膨胀/\" target=\"_blank\">形态学转换</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#腐蚀\" data-toc-modified-id=\"腐蚀-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>腐蚀</a></span></li><li><span><a href=\"#膨胀\" data-toc-modified-id=\"膨胀-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>膨胀</a></span></li><li><span><a href=\"#开运算\" data-toc-modified-id=\"开运算-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>开运算</a></span></li><li><span><a href=\"#闭运算\" data-toc-modified-id=\"闭运算-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>闭运算</a></span></li><li><span><a href=\"#形态学梯度\" data-toc-modified-id=\"形态学梯度-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>形态学梯度</a></span></li><li><span><a href=\"#顶帽\" data-toc-modified-id=\"顶帽-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>顶帽</a></span></li><li><span><a href=\"#黑帽\" data-toc-modified-id=\"黑帽-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>黑帽</a></span></li><li><span><a href=\"#小结\" data-toc-modified-id=\"小结-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>小结</a></span></li></ul></li><li><span><a href=\"#图像轮廓\" data-toc-modified-id=\"图像轮廓-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>图像轮廓</a></span><ul class=\"toc-item\"><li><span><a href=\"#寻找轮廓\" data-toc-modified-id=\"寻找轮廓-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>寻找轮廓</a></span></li><li><span><a href=\"#绘制轮廓\" data-toc-modified-id=\"绘制轮廓-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>绘制轮廓</a></span></li><li><span><a href=\"#轮廓特征\" data-toc-modified-id=\"轮廓特征-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span><a href=\"http://ex2tron.wang/2017/12/20/Python-OpenCV教程14：轮廓特征/\" target=\"_blank\">轮廓特征</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#直边界矩阵\" data-toc-modified-id=\"直边界矩阵-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>直边界矩阵</a></span></li><li><span><a href=\"#旋转的边界矩形\" data-toc-modified-id=\"旋转的边界矩形-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>旋转的边界矩形</a></span></li><li><span><a href=\"#最小外接圆\" data-toc-modified-id=\"最小外接圆-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>最小外接圆</a></span></li><li><span><a href=\"#拟合椭圆\" data-toc-modified-id=\"拟合椭圆-6.3.4\"><span class=\"toc-item-num\">6.3.4&nbsp;&nbsp;</span>拟合椭圆</a></span></li><li><span><a href=\"#形状匹配\" data-toc-modified-id=\"形状匹配-6.3.5\"><span class=\"toc-item-num\">6.3.5&nbsp;&nbsp;</span>形状匹配</a></span></li></ul></li><li><span><a href=\"#小结：\" data-toc-modified-id=\"小结：-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>小结：</a></span></li></ul></li><li><span><a href=\"#直方图\" data-toc-modified-id=\"直方图-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>直方图</a></span><ul class=\"toc-item\"><li><span><a href=\"#术语\" data-toc-modified-id=\"术语-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>术语</a></span></li><li><span><a href=\"#计算直方图\" data-toc-modified-id=\"计算直方图-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>计算直方图</a></span><ul class=\"toc-item\"><li><span><a href=\"#OpenCV中直方图计算\" data-toc-modified-id=\"OpenCV中直方图计算-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>OpenCV中直方图计算</a></span></li><li><span><a href=\"#Numpy中直方图计算\" data-toc-modified-id=\"Numpy中直方图计算-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Numpy中直方图计算</a></span></li><li><span><a href=\"#绘制直方图\" data-toc-modified-id=\"绘制直方图-7.2.3\"><span class=\"toc-item-num\">7.2.3&nbsp;&nbsp;</span>绘制直方图</a></span></li><li><span><a href=\"#直方图均衡化\" data-toc-modified-id=\"直方图均衡化-7.2.4\"><span class=\"toc-item-num\">7.2.4&nbsp;&nbsp;</span><a href=\"https://zh.wikipedia.org/wiki/直方图均衡化\" target=\"_blank\">直方图均衡化</a></a></span></li><li><span><a href=\"#自适应均衡化\" data-toc-modified-id=\"自适应均衡化-7.2.5\"><span class=\"toc-item-num\">7.2.5&nbsp;&nbsp;</span>自适应均衡化</a></span></li></ul></li></ul></li><li><span><a href=\"#模板匹配\" data-toc-modified-id=\"模板匹配-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>模板匹配</a></span><ul class=\"toc-item\"><li><span><a href=\"#模板匹配的6种比较方法\" data-toc-modified-id=\"模板匹配的6种比较方法-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>模板匹配的6种比较方法</a></span></li><li><span><a href=\"#模板匹配函数\" data-toc-modified-id=\"模板匹配函数-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span><a href=\"https://www.cnblogs.com/FHC1994/p/9123393.html\" target=\"_blank\">模板匹配函数</a></a></span></li></ul></li><li><span><a href=\"#霍夫变换\" data-toc-modified-id=\"霍夫变换-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span><a href=\"https://blog.csdn.net/on2way/article/details/47028969\" target=\"_blank\">霍夫变换</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#霍夫直线变换\" data-toc-modified-id=\"霍夫直线变换-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>霍夫直线变换</a></span></li><li><span><a href=\"#统计概率霍夫直线变换\" data-toc-modified-id=\"统计概率霍夫直线变换-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>统计概率霍夫直线变换</a></span></li><li><span><a href=\"#霍夫圆变换\" data-toc-modified-id=\"霍夫圆变换-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>霍夫圆变换</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [图像阈值](http://ex2tron.wang/2017/12/07/Python-OpenCV%E6%95%99%E7%A8%8B6%EF%BC%9A%E9%98%88%E5%80%BC%E5%88%86%E5%89%B2/)\n",
    "\n",
    "### 简单阈值\n",
    "> 整幅图像采用同一个数作为阈值（全局阈值）。像素值高于阈值时，给这个像素赋予一个新值（可能是白色），否则我们给它赋予另外一种颜色（也许是黑色）。这个函数就是 cv2.threshhold()。\n",
    "\n",
    ">>函数原型:  \n",
    "```\n",
    "threshold(src, thresh, maxval, type[, dst]) -> retval, dst\n",
    "```\n",
    ">* 第一个参数就是原图像，原图像应该是灰度图  \n",
    ">* 第二个参数就是用来对像素值进行分类的阈值  \n",
    ">* 第三个参数就是当像素值高于（有时是小于）阈值时应该被赋予的新的像素值   \n",
    ">* OpenCV提供了多种不同的阈值方法，这是有第四个参数来决定的。这些方法包括： \n",
    "\n",
    "\n",
    ">>阈值类型一般分为五种： \n",
    "```\n",
    "cv2.THRESH_BINARY —— 大于阈值的部分像素值变为最大值，其他变为0   \n",
    "cv2.THRESH_BINARY_INV —— 大于阈值的部分变为0，其他部分变为最大值   \n",
    "cv2.THRESH_TRUNC —— 大于阈值的部分变为阈值，其余部分不变   \n",
    "cv2.THRESH_TOZERO —— 大于阈值的部分不变，其余部分变为0   \n",
    "cv2.THRESH_TOZERO_INV —— 大于阈值的部分变为0，其余部分不变  \n",
    "```\n",
    "\n",
    "### 自适应阈值\n",
    "> 当同一幅图像上的不同部分的具有不同亮度时，这种情况下需要采用自适应阈值。此时的阈值是根据图像上的每一个小区域计算与其对应的阈值。因此在同一幅图像上的不同区域采用的是不同的阈值，从而能在亮度不同的情况下得到更好的结果\n",
    "\n",
    "\n",
    ">>函数原型:\n",
    "```\n",
    "adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) -> dst\n",
    "```\n",
    ">* 参数1：要处理的原图  \n",
    ">* 参数2：最大阈值，一般为255  \n",
    ">* 参数3：小区域阈值的计算方式  \n",
    "     ADAPTIVE_THRESH_MEAN_C：小区域内取均值    \n",
    "     ADAPTIVE_THRESH_GAUSSIAN_C：小区域内加权求和，权重是个高斯核\n",
    ">* 参数4：阈值方式（跟前面讲的那5种相同）\n",
    ">* 参数5：邻域的面积，如11就是11x11的小块\n",
    ">* 参数6：一个常数，最终阈值等于小区域计算出的阈值再减去此值\n",
    "\n",
    "### [Otsu's 二值化](http://ex2tron.wang/2017/12/08/Python-OpenCV%E6%95%99%E7%A8%8B%E7%95%AA%E5%A4%96%E7%AF%874%EF%BC%9AOtsu%E9%98%88%E5%80%BC%E6%B3%95/)\n",
    "> 如果是一幅双峰图像（双峰图像是指图像直方图中存在两个峰）应该在两个峰之间的峰谷选一个值作为阈值。这就是 Otsu 二值化要做的。简单来说就是对一幅双峰图像自动根据其直方图计算出一个阈值。（对于非双峰图像，这种方法得到的结果可能会不理想）\n",
    "\n",
    "> 用到到的函数还是 cv2.threshold()，但是需要多传入一个参数（flag）： cv2.THRESH_OTSU。这时要把阈值设为 0。然后算法会找到最优阈值，这个最优阈值就是返回值 retVal。如果不使用 Otsu 二值化，返回的retVal 值与设定的阈值相等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [滤波和模糊](http://ex2tron.wang/2017/12/15/Python-OpenCV%E6%95%99%E7%A8%8B10%EF%BC%9A%E5%B9%B3%E6%BB%91%E5%9B%BE%E5%83%8F/)\n",
    "\n",
    "> 过滤是信号和图像处理中基本的任务。其目的是根据应用环境的不同，选择性的提取图像中某些认为是重要的信息。过滤可以移除图像中的噪音、提取感兴趣的可视特征、允许图像重采样等等。频域分析将图像分成从低频到高频的不同部分。低频对应图像强度变化小的区域，而高频是图像强度变化非常大的区域。在频率分析领域的框架中，滤波器是一个用来增强图像中某个波段或频率并阻塞（或降低）其他频率波段的操作。低通滤波器是消除图像中高频部分，但保留低频部分。高通滤波器消除低频部分；模糊操作就是过滤掉图像中的一些特殊噪音\n",
    "* 低通滤波器（lowpass）是模糊，减弱或阻隔高频信号，保留低频信号    \n",
    "* 高通滤波器（highpass）是锐化，减弱或阻隔低频信号，保留高频信号  \n",
    "\n",
    ">> 低通滤波器就是允许低频信号通过，在图像中边缘和噪点都相当于高频部分，所以低通滤波器用于去除噪点、平滑和模糊图像。\n",
    "高通滤波器则反之，用来增强图像边缘，进行锐化处理\n",
    "\n",
    ">> 常见噪声有椒盐噪声和高斯噪声，椒盐噪声可以理解为斑点，随机出现在图像中的黑点或白点；高斯噪声可以理解为拍摄图片时由于光照等原因造成的噪声；这样解释并不准确，只要能简单分辨即可\n",
    "\n",
    "> 使用低通滤波器可以达到图像模糊的目的。这对与去除噪音很有帮助。其实就是去除图像中的高频成分（比如：噪音，边界）。所以边界也会被模糊一点。（当然，也有一些模糊技术不会模糊掉边界）。 OpenCV 提供了四种模糊技术\n",
    "\n",
    "### 均值滤波\n",
    "> 均值滤波是一种最简单的滤波处理，它取的是卷积核区域内元素的均值，用cv2.blur()实现：\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "blur(src, ksize[, dst[, anchor[, borderType]]]) -> dst\n",
    "```\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "img = cv2.imread('img/lena.jpg')\n",
    "img = cv2.blur(img, (3, 3))   # 使用 3×3的卷积核\n",
    "```\n",
    "\n",
    "### 方框滤波\n",
    "> 方框滤波跟均值滤波很像，用cv2.boxFilter()函数实现，事实上，当可选参数normalize为True的时候，方框滤波就是均值滤波；normalize为False的时候，相当于求区域内的像素和\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "boxFilter(src, ddepth, ksize[, dst[, anchor[, normalize[, borderType]]]]) -> dst\n",
    "```\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "* 前面的均值滤波也可以用方框滤波实现：normalize=True\n",
    "blur = cv2.boxFilter(img, -1, (3, 3), normalize=True)\n",
    "```\n",
    "\n",
    "### [高斯滤波](http://www.ruanyifeng.com/blog/2012/11/gaussian_blur.html)\n",
    "> 高斯滤波器是一种线性滤波器，能够有效的抑制噪声，平滑图像。把卷积核换成高斯核（简单来说，方框不变，将原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包。原来的求平均数现在变成求加权平均数，全就是方框里的值）。实现的函数是 cv2.GaussianBlur()。需要指定高斯核的宽和高（必须是奇数）。以及高斯函数沿 X， Y 方向的标准差。如果只指定了 X 方向的的标准差， Y 方向也会取相同值。如果两个标准差都是 0，那么函数会根据核函数的大小自己计算。高斯滤波可以有效的从图像中去除高斯噪音\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "img = cv2.GaussianBlur(img, (5, 5), 1) # 使用 5×5的高斯核\n",
    "```\n",
    "\n",
    "> 注：高斯滤波相比均值滤波效率要慢，但可以有效消除高斯噪声，能保留更多的图像细节，所以经常被称为最有用的滤波器。\n",
    "\n",
    "### 中值滤波\n",
    "> 中值又叫中位数，是所有值排序后取中间的值。中值滤波就是用区域内的中值来代替本像素值，所以那种孤立的斑点，如0或255很容易消除掉，适用于去除椒盐噪声和斑点噪声。中值是一种非线性操作，效率相比前面几种线性滤波要慢。\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "medianBlur(src, ksize[, dst]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "img = cv2.medianBlur(img, 5)   \n",
    "```\n",
    "\n",
    "### 双边滤波\n",
    "> 已知道高斯滤波器是求中心点邻近区域像素的高斯加权平均值。这种高斯滤波器只考虑像素之间的空间关系，而不会考虑像素值之间的关系（像素的相似度）。所以这种方法不会考虑一个像素是否位于边界，因此边界也会别模糊掉。\n",
    "函数 cv2.bilateralFilter() 能在保持边界清晰的情况下有效的去除噪音，但是这种操作与其他滤波器相比会比较慢；双边滤波在同时使用`*空间高斯权重*`和`*灰度值相似性高斯权重*`；空间高斯函数确保只有邻近区域的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以这种方法会确保边界不会被模糊掉，因为边界处的灰度值变化比较大\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "img = cv2.bilateralFilter(img, 9, 75, 75)   \n",
    "```\n",
    "\n",
    "### 小结\n",
    "* 在不知道用什么滤波器好的时候，优先高斯滤波 cv2.GaussianBlur()，然后均值滤波 cv2.blur()\n",
    "* 斑点和椒盐噪声优先使用中值滤波 cv2.medianBlur()\n",
    "* 要去除噪点的同时尽可能保留更多的边缘信息，使用双边滤波 cv2.bilateralFilter()\n",
    "* 线性滤波方式：均值滤波、方框滤波、高斯滤波（速度相对快）\n",
    "* 非线性滤波方式：中值滤波、双边滤波（速度相对慢）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 边缘检测的步骤\n",
    "> * 滤波: 消除噪音  \n",
    "边缘检测的算法主要是基于图像强度的一阶和二阶导数，但导数通常对噪声很敏感，因此必须采用滤波器来改善与噪声有关的边缘检测器的性能。常见的滤波方法主要有`高斯滤波`，即采用离散化的高斯函数产生一组归一化的高斯核，然后基于高斯核函数对图像灰度矩阵的每一点进行加权求和\n",
    "\n",
    "> * 增强: 使边界轮廓更加明显  \n",
    "增强边缘的基础是确定图像各点邻域强度的变化值。增强算法可以将图像灰度点邻域强度值有显著变化的点凸显出来。在具体编程实现时，可通过计算`梯度幅值`来确定\n",
    "\n",
    "> * 检测: 选出边缘点  \n",
    "经过增强的图像，往往邻域中有很多点的梯度值比较大，而在特定的应用中，这些点并不是我们要找的边缘点，所以应该采用某种方法来对这些点进行取舍。实际工程中，常用的方法是通过`阈值化`方法来检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [图像梯度](http://ex2tron.wang/2017/12/18/Python-OpenCV教程番外篇8：图像梯度/)\n",
    "\n",
    "> 把图片想象成连续函数，因为边缘部分的像素值是与旁边像素明显有区别的，所以对图片局部求极值，就可以得到整幅图片的边缘信息了。不过图片是二维的离散函数，导数就变成了差分，这个差分就称为[图像的梯度](https://blog.csdn.net/saltriver/article/details/78987096)\n",
    "\n",
    "> 当用均值滤波器降低图像噪声的时候，会带来图像模糊的副作用。那么，清晰图像和模糊图像之间的差别在哪里呢？从逻辑上考虑，图像模糊是因为图像中物体的轮廓不明显，轮廓边缘灰度变化不强烈，层次感不强造成的，那么反过来考虑，轮廓边缘灰度变化明显些，层次感强些的图像就更清晰些。\n",
    "那么，这种灰度变化明显不明显怎样去定义呢。知道微分就是求函数的变化率，即导数（梯度），那么对于图像来说，可以用微分来表示图像灰度的变化率；因为图像是一个离散的二维函数f(x, y)，其微分就是偏微分\n",
    "\n",
    "> 如果相邻像素灰度值有变化，那么梯度就有值，如果相邻像素灰度值没有变化，那么梯度就为0。如果把梯度值与对应的像素相加，那么灰度值没有变化的，像素值不变，而有梯度值的，灰度值变大了；对比度显然增强了，尤其是图像中物体的轮廓和边缘，与背景大大加强了区别，这就是用梯度来增强图像的原理\n",
    "\n",
    "### Soble算子\n",
    "\n",
    "> Sobel 算子是`高斯平滑`与`微分操作`的结合体，所以它的抗噪声能力很好。可以设定求导的方向（xorder 或 yorder）。还可以设定使用的卷积核的大小（ksize）。如果 ksize=-1，会使用 3x3 的 Scharr 滤波器，它的的效果要比 3x3 的 Sobel 滤波器好（而且速度相同，所以在使用 3x3 滤波器时应该尽量使用 Scharr 滤波器）\n",
    "\n",
    "> * sobel算子在水平和垂直方向两个方向上作边缘检测运算\n",
    "> * sobel算子也同上一篇博文中提到的边缘检测算法一样，在水平和垂直方向两个方向上作边缘检测运算\n",
    "> * sobel算对噪声具有平滑作用，提供较为精确的边缘方向信息，边缘定位精度不够高。当对精度要求不是很高时，是一种较为常用的边缘检测方法\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "sobelX = cv2.Sobel(image,cv2.CV_64F,1,0)          # x方向的梯度\n",
    "sobelY = cv2.Sobel(image,cv2.CV_64F,0,1)          # y方向的梯度\n",
    "sobelX = np.uint8(np.absolute(sobelX))            # x方向梯度的绝对值\n",
    "sobelY = np.uint8(np.absolute(sobelY))            # y方向梯度的绝对值\n",
    "sobelCombined = cv2.bitwise_or(sobelX,sobelY)     # 合并\n",
    "```\n",
    "\n",
    ">> [示例](https://blog.csdn.net/GarfieldEr007/article/details/51326218):\n",
    "```python\n",
    "import cv2  \n",
    "import numpy as np    \n",
    "img = cv2.imread(\"D:/lion.jpg\", 0)  \n",
    "x = cv2.Sobel(img,cv2.CV_16S,1,0)  \n",
    "y = cv2.Sobel(img,cv2.CV_16S,0,1)  \n",
    "absX = cv2.convertScaleAbs(x)                     # 转回uint8  \n",
    "absY = cv2.convertScaleAbs(y)  \n",
    "dst = cv2.addWeighted(absX,0.5,absY,0.5,0)  \n",
    "cv2.imshow(\"absX\", absX)  \n",
    "cv2.imshow(\"absY\", absY)  \n",
    "cv2.imshow(\"Result\", dst)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  \n",
    "```\n",
    "\n",
    "> 解释:\n",
    "\n",
    ">> 在Sobel函数的第二个参数这里使用了`cv2.CV_16S`。因为OpenCV文档中对Sobel算子的介绍中有这么一句：“in the case of 8-bit input images it will result in truncated derivatives”。即Sobel函数求完导数后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，所以Sobel建立的图像位数不够，会有截断。因此要使用16位有符号的数据类型，即cv2.CV_16S。\n",
    "\n",
    ">> 在经过处理后，别忘了用`cv2.convertScaleAbs()`函数将其转回原来的uint8形式。否则将无法显示图像，而只是一副灰色的窗口。convertScaleAbs()的原型为：convertScaleAbs(src[, dst[, alpha[, beta]]]) -> dst； 其中可选参数alpha是伸缩系数，beta是加到结果上的一个值。结果返回uint8类型的图片\n",
    "\n",
    ">> 由于Sobel算子是在两个方向计算的，最后还需要用`cv2.addWeighted`函数将其组合起来。其函数原型为：addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) -> dst；其中alpha是第一幅图片中元素的权重，beta是第二个的权重，gamma是加到最后结果上的一个值\n",
    "\n",
    "\n",
    "### Scharr算子\n",
    "\n",
    "> Scharr函数只是比Sobel函数少了个ksize的参数，原因是它的ksize是定值3\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "Scharr(src, ddepth, dx, dy[, dst[, scale[, delta[, borderType]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "grad_x = cv.Scharr(image, cv.CV_32F, 1, 0)   #对x求一阶导\n",
    "grad_y = cv.Scharr(image, cv.CV_32F, 0, 1)   #对y求一阶导\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### [Laplacian算子](https://blog.csdn.net/sunny2038/article/details/9188441)\n",
    "\n",
    "> 图像中的边缘区域，像素值会发生“跳跃”，对这些像素求导，在其一阶导数在边缘位置为极值，这就是Sobel算子使用的原理——极值处就是边缘。如果对像素值求二阶导数，会发现边缘处的导数值为0；Laplace函数实现的方法是先用Sobel 算子计算二阶x和y导数，再求和\n",
    "\n",
    "> 边缘检测本身属于锐化操作，对噪点比较敏感，所以需要进行平滑处理，通常对图像先进行低通滤波（高斯模糊处理），再使用 Laplacian算子\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst\n",
    "```\n",
    ">> * 第一个参数是需要处理的图像\n",
    ">> * 第二个参数是图像的深度，-1表示采用的是与原图像相同的深度。目标图像的深度必须大于等于原图像的深度\n",
    ">> * 可选参数：ksize是算子的大小，必须为1、3、5、7。默认为1\n",
    ">> * 可选参数：scale是缩放导数的比例常数，默认情况下没有伸缩系数\n",
    ">> * 可选参数：delta是一个可选的增量，将会加到最终的dst中，同样，默认情况下没有额外的值加到dst中\n",
    ">> * 可选参数：borderType是判断图像边界的模式。这个参数默认值为cv2.BORDER_DEFAULT\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "gray_lap = cv2.Laplacian(img, cv2.CV_16S, ksize = 3)  \n",
    "dst = cv2.convertScaleAbs(gray_lap)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [形态学转换](http://ex2tron.wang/2017/12/19/Python-OpenCV教程12：腐蚀与膨胀/)\n",
    "\n",
    "> 形态学操作是根据图像形状进行的简单操作（改变物体的形状）。一般情况下对二值化图像进行的操作。需要输入两个参数，一个是原始图像，第二个被称为结构化元素或核，它是用来决定操作的性质的。  \n",
    "两个基本的形态学操作是腐蚀和膨胀。他们的变体构成了开运算，闭运算，梯度等  \n",
    "形态学操作一般作用于二值化图，来连接相邻的元素或分离成独立的元素。腐蚀和膨胀是针对图片中的白色部分！  \n",
    "\n",
    "### 腐蚀\n",
    "> 就像土壤侵蚀一样，这个操作会把前景物体的边界腐蚀掉（但是前景仍然是白色）。卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是 1，那么中心元素就保持原来的像素值，否则就变为零。  \n",
    "根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为 0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪声很有用，也可以用来断开两个连在一块的物体等  \n",
    "总结： 腐蚀的效果是把图片”变瘦”，其原理是在原图的小区域内取局部最小值。因为是二值化图，只有0和255，所以小区域内有一个是0该像素点就为0\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "erode(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "erosion = cv2.erode(img, kernel, iterations=1)\n",
    "```\n",
    ">> 补充：  \n",
    ">>>这个核 kernel 也叫结构元素，因为形态学操作其实也是应用卷积来实现的。结构元素可以是矩形/椭圆/十字形，可以用cv2.getStructuringElement()来生成不同形状的结构元素，比如：\n",
    "```python\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))     # 矩形结构\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # 椭圆结构\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5))    # 十字形结构\n",
    "```\n",
    "\n",
    "\n",
    "### 膨胀\n",
    "> 与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是 1，中心元素的像素值就是 1。所以这个操作会增加图像中的白色区域（前景）。一般在去\n",
    "噪声时先用腐蚀再用膨胀。因为腐蚀在去掉白噪声的同时，也会使前景对象变小。所以需要再对他进行膨胀。这时噪声已经被去除了，不会再回来了，但是前景还在并会增加。膨胀也可以用来连接两个分开的物体  \n",
    "总结：膨胀与腐蚀相反，取的是局部最大值，效果是把图片”变胖”\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "dilate(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilation = cv2.dilate(img, kernel, iterations = 1)\n",
    "```\n",
    "\n",
    "### 开运算\n",
    "> 先腐蚀后膨胀叫开运算（因为先腐蚀会分开物体），其作用是：分离物体，消除小区域\n",
    "\n",
    ">> 函数原型:\n",
    "```python\n",
    "morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
    "```\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "```\n",
    "\n",
    "### 闭运算\n",
    "> 先膨胀再腐蚀。它经常被用来填充前景物体中的小洞，或者前景物体上的小黑点\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "```\n",
    "\n",
    "### 形态学梯度\n",
    "> 就是一幅图像膨胀与腐蚀的差别。膨胀图减去腐蚀图，dilation - erosion，这样会得到物体的轮廓\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "```\n",
    "\n",
    "### 顶帽\n",
    "> 原图减去开运算（先腐蚀再膨胀）后的图：src - opening\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "```\n",
    "\n",
    "### 黑帽\n",
    "> 闭运算（先膨胀再腐蚀）后的图减去原图：closing - src\n",
    "\n",
    ">> 示例:\n",
    "```python\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "```\n",
    "\n",
    "### 小结\n",
    "* 形态学操作就是改变物体的形状，如腐蚀使物体”变瘦”，膨胀使物体”变胖”\n",
    "* 先腐蚀后膨胀会分离物体，所以叫开运算，常用来去除小区域物体\n",
    "* 先膨胀后腐蚀会消除物体内的小洞，所以叫闭运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像轮廓\n",
    "\n",
    "> 轮廓可以简单认为成将连续的点（连着边界）连在一起的曲线，具有相同的颜色或者灰度。轮廓在形状分析和物体的检测和识别中很有用。\n",
    "* 为了更加准确，要使用二值化图像。在寻找轮廓之前，要进行阈值化处理或者 Canny 边界检测。\n",
    "* 查找轮廓的函数会修改原始图像。如果在找到轮廓之后还想使用原始图像的话，应该将原始图像存储到其他变量中\n",
    "* 在 OpenCV 中，查找轮廓就像在黑色背景中超白色物体。应该记住，要找的物体应该是白色而背景应该是黑色（寻找轮廓是针对白色物体的）\n",
    "\n",
    "> 谈起轮廓容易想起边缘，它们确实很像。简单的说，轮廓是连续的，边缘并不全都连续。其实边缘主要是作为图像的特征使用，比如可以用边缘特征可以区分脸和手，而轮廓主要用来分析物体的形态，比如物体的周长和面积等，可以说边缘包括轮廓\n",
    "* 边缘检测主要是通过一些手段检测数字图像中明暗变化剧烈（即梯度变化比较大）像素点，偏向于图像中像素点的变化。如canny边缘检测，结果通常保存在和源图片一样尺寸和类型的边缘图中\n",
    "* 轮廓检测指检测图像中的对象边界，更偏向于关注上层语义对象。轮廓可能是边缘的一部分\n",
    "* 在做图像的轮廓检测时通常可以先检测边缘，再将检测到的边缘进行进一步处理，得到图像的轮廓\n",
    "\n",
    "### 寻找轮廓\n",
    "> 函数原型:\n",
    "```python\n",
    "findContours(image, mode, method[, contours[, hierarchy[, offset]]]) -> image, contours, hierarchy\n",
    "```\n",
    "\n",
    ">参数说明：\n",
    "* mode: 轮廓检索模式（Contour Retrieval Mode）\n",
    ">>* `cv2.RETR_LIST` - 最简单的一种寻找方式，它不建立轮廓间的子属关系，也就是所有轮廓都属于同一层级；hierarchy中的后两个值[First Child, Parent]都为-1  \n",
    ">>* `cv2.RETR_TREE` - 会完整建立轮廓的层级从属关系  \n",
    ">>* `cv2.RETR_EXTERNAL` - 这种方式只寻找最高层级的轮廓，也就是它只会找到0级轮廓  \n",
    ">>* `cv2.RETR_CCOMP` - 把所有的轮廓只分为2个层级，不是外层的就是里层的   \n",
    "* method: 轮廓的近似方法\n",
    ">>* `cv2.CHAIN_APPROX_NONE` - 存储所有的轮廓点，相邻的两个点的像素位置差不超过1，即max(abs(x1-x2), abs(y2-y1))==1\n",
    ">>* `cv2.CHAIN_APPROX_SIMPLE` - 压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需4个点来保存轮廓信息  \n",
    "\n",
    ">[返回值说明:](https://blog.csdn.net/sunny2038/article/details/12889059)\n",
    "* image:  还是原来的二值化图片\n",
    "* contours: 存储的是一个list，list中每个元素都是图像中的一个轮廓，用numpy中的ndarray表示\n",
    "* hierarchy: 包含两个ndarray，每个ndarray对应一个轮廓（元素个数和轮廓个数相同），每个轮廓有四个属性[Next, Previous, First Child, Parent]；，每个轮廓contours[i]对应4个hierarchy元素hierarchy[i][0] ~hierarchy[i][3]，分别表示后一个轮廓、前一个轮廓、父轮廓、内嵌轮廓的索引编号，如果没有对应项，则该值为负数-1\n",
    ">>* `Next`：与当前轮廓处于同一层级的下一条轮廓\n",
    ">>* `Previous`：与当前轮廓处于同一层级的上一条轮廓\n",
    ">>* `First Child`：当前轮廓的第一条子轮廓\n",
    ">>* `Parent`：当前轮廓的父轮廓\n",
    "\n",
    "> 示例:\n",
    "```python\n",
    "img = cv2.imread('handwriting.jpg')\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "```\n",
    "\n",
    "### 绘制轮廓\n",
    "> 函数原型:\n",
    "```python\n",
    "drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]) -> image\n",
    "```\n",
    "\n",
    ">参数说明：\n",
    "* image: 指明在哪幅图像上绘制轮廓\n",
    "* contours： 指明轮廓，在Python中是一个list\n",
    "* contourIdx: 指定绘制轮廓list中的哪条轮廓，如果是-1，则绘制其中的所有轮廓\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "cv2.drawContour(img, contours, -1, (0,255,0), 3)      # 绘制所有轮廓\n",
    "cv2.drawContour(img, contours, 1, (0,255,0), 3)       # 绘制第二条轮廓\n",
    "```\n",
    "\n",
    "### [轮廓特征](http://ex2tron.wang/2017/12/20/Python-OpenCV教程14：轮廓特征/)\n",
    "\n",
    "#### 直边界矩阵\n",
    "> 一个直矩形（就是没有旋转的矩形）。它不会考虑对象是否旋转。所以边界矩形的面积不是最小的\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "boundingRect(points) -> retval  \n",
    "```\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "image = cv2.imread('handwriting.jpg', 0)\n",
    "_, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "image, contours, hierarchy = cv2.findContours(thresh, 3, 2)  \n",
    "x,y,w,h = cv2.boundingRect(contours[0])      # 外接矩形\n",
    "img = cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "```\n",
    "> 返回值说明：\n",
    "```python  \n",
    " (x, y) 为矩形左上角的坐标\n",
    " (w, h) 为矩形的宽和高\n",
    "```\n",
    "\n",
    "#### 旋转的边界矩形\n",
    "> 这个边界矩形是面积最小的，因为它考虑了对象的旋转。用到的函数为 cv2.minAreaRect()。返回的是一个 Box2D 结构，其中包含矩形左上角角点的坐标（x， y），矩形的宽和高（w， h），以及旋转角度。但是要绘制这个矩形需要矩形的 4 个角点，可以通过函数 cv2.boxPoints() 获\n",
    "得。\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "minAreaRect(points) -> retval \n",
    "```\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "rect = cv2.minAreaRect(contours[0])              # 最小外接矩形\n",
    "box = np.int0(cv2.boxPoints(rect))               # 矩形的四个角点取整\n",
    "cv2.drawContours(img_color1, [box], 0, (255, 0, 0), 2)\n",
    "```\n",
    "> 函数说明：\n",
    "```python  \n",
    "  其中np.int0(x)是把x取整的操作，比如377.93就会变成377，也可以用x.astype(np.int)\n",
    "```\n",
    "\n",
    "#### 最小外接圆\n",
    "> 函数 cv2.minEnclosingCircle() 可以帮我们找到一个对象的外切圆。它是所有能够包括对象的圆中面积最小的一个。\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "minEnclosingCircle(points) -> center, radius\n",
    "```\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "(x, y), radius = cv2.minEnclosingCircle(contours[0])\n",
    "(x, y, radius) = np.int0((x, y, radius))            # 返回圆心和半径取整\n",
    "cv2.circle(img_color2, (x, y), radius, (0, 0, 255), 2)\n",
    "```\n",
    "\n",
    "#### 拟合椭圆\n",
    "> 用的函数为 cv2.ellipse()，返回值其实就是旋转边界矩形的内切圆\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "fitEllipse(points) -> retval\n",
    "```\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "ellipse = cv2.fitEllipse(contours[0])\n",
    "cv2.ellipse(img_color2, ellipse, (255, 255, 0), 2)\n",
    "```\n",
    "\n",
    "#### 形状匹配\n",
    "> cv2.matchShapes()可以检测两个形状之间的相似度，返回值越小，越相似\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "matchShapes(contour1, contour2, method, parameter) -> retval\n",
    "```\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "img = cv2.imread('shapes.jpg', 0)\n",
    "_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "_, contours, hierarchy = cv2.findContours(thresh, 3, 2)\n",
    "cnt_a, cnt_b, cnt_c = contours[0], contours[1], contours[2]\n",
    "print cv2.matchShapes(cnt_b, cnt_b, 1, 0.0)       # 0.0\n",
    "print cv2.matchShapes(cnt_b, cnt_c, 1, 0.0)       # 2.17e-05\n",
    "print cv2.matchShapes(cnt_b, cnt_a, 1, 0.0)       # 0.418\n",
    "```\n",
    "\n",
    "### 小结：\n",
    "常用的轮廓特征：\n",
    "* cv2.contourArea()算面积，cv2.arcLength()算周长，cv2.boundingRect()算外接矩\n",
    "* cv2.minAreaRect()算最小外接矩，cv2.minEnclosingCircle()算最小外接圆\n",
    "* cv2.matchShapes()进行形状匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直方图\n",
    "\n",
    "> 直方图简单来说就是图像中每个像素值的个数统计，比如说一副灰度图中像素值为0的有多少个，1的多少个…… 直方图是一种分析图片的手段。\n",
    "通过直方图你可以对整幅图像的灰度分布有一个整体的了解。直方图的 x 轴是灰度值（0 到 255）， y 轴是图片中具有同一个灰度值的点的数目\n",
    "（要记住，直方图是根据灰度图像绘制的，而不是彩色图像）。直方图的左边区域像是了暗一点的像素数量，右侧显示了亮一点的像素的数量。\n",
    "\n",
    "### 术语\n",
    "* dims：要计算的通道数，对于灰度图dims=1\n",
    "* range：要计算的像素值范围，一般为[0,256]（不包括256），也就是说所有的灰度值\n",
    "* bins：子区段数目，如果我们统计0~255每个像素值，bins=256；如果划分区间，比如0~15, 16~31…240~255这样16个区间，bins=16\n",
    "\n",
    "### 计算直方图\n",
    "#### OpenCV中直方图计算\n",
    "> 函数原型:\n",
    "```python\n",
    "calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]]) -> hist\n",
    "```\n",
    "\n",
    "> 参数说明:\n",
    "```python\n",
    "* images: 原图像（图像格式为 uint8 或 float32）。当传入函数时应该用中括号`[]`括起来，例如： [img]\n",
    "* channels: 同样需要用中括号括起来，它会告诉函数我们要统计那幅图像的直方图。如果输入图像是灰度图，它的值就是[0]; 如果是彩色图像的话，传入的参数可以是 [0]， [1]， [2] 它们分别对应着通道 B， G， R\n",
    "* mask: 掩模图像。要统计整幅图像的直方图就把它设为 None。但是如果你想统计图像某一部分的直方图的话，你就需要制作一个掩模图像，并使用它。\n",
    "* histSize: bins 的数目。也应该用中括号括起来，例如：[256]。\n",
    "* ranges:  像素值范围，通常为 [0， 256]\n",
    "```\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "img = cv2.imread('hist.jpg', 0)\n",
    "hist = cv2.calcHist([img], [0], None, [256], [0, 256])   # 注: 只有mask没有中括号\n",
    "```\n",
    "\n",
    "#### Numpy中直方图计算\n",
    "> 函数原型:\n",
    "```python\n",
    "np.histogram(a, bins=10, range=None, normed=None, weights=None, density=None)\n",
    "```\n",
    "\n",
    "> 参数说明:\n",
    "```python\n",
    "* a: 扁平数组\n",
    "* bins: bins 的数目。也应该用中括号括起来，例如：[256]。\n",
    "* ranges:  像素值范围，通常为 [0， 256]\n",
    "```\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "img = cv2.imread('hist.jpg', 0)\n",
    "hist, bins = np.histogram(img.ravel(), 256, [0, 256])   # 注: 函数ravel()将二维矩阵展平变成一维数组\n",
    "```\n",
    "\n",
    "#### 绘制直方图\n",
    "> 示例：（使用 matplotlib 绘制多通道（BGR）直方图）\n",
    "```python\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv2.imread('home.jpg')\n",
    "color = ('b', 'g', 'r')\n",
    "for i, col in enumerate(color):\n",
    "    histr = cv2.calcHist([img], [i], None, [256], [0, 256])\n",
    "    plt.plot(histr, color=col)\n",
    "    plt.xlmin([0, 256])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### [直方图均衡化](https://zh.wikipedia.org/wiki/直方图均衡化)\n",
    "> 直方图均衡化(Histogram Equalization) 又称直方图平坦化,实质上是对图像进行非线性拉伸,重新分配图像象元值,使一定灰度范围内象元值的数量大致相等。这样,原来直方图中间的峰顶部分对比度得到增强,而两侧的谷底部分对比度降低,输出图像的直方图是一个较平的分段直方图:如果输出数据分段值较小的话,会产生粗略分类的视觉效果。  \n",
    "> 将随机分布的图像直方图修改成均匀分布的直方图。基本思想是对原始图像的像素灰度做某种映射变换, 使变换后图像灰度的概率密度呈均匀分布。这就意味着图像灰度的动态范围得到了增加, 提高了图像的对比度  \n",
    "> 通过这种技术可以清晰地在直方图上看到图像亮度的分布情况, 并可按照需要对图像亮度调整。另外,这种方法是可逆的, 如果已知均衡化函数, 就可以恢复原始直方图。\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "equalizeHist(src[, dst]) -> dst\n",
    "```\n",
    "> 示例:  \n",
    "```python\n",
    "img = cv2.imread('hist.jpg', 0)\n",
    "equ = cv2.equalizeHist(img)\n",
    "cv2.imshow('equalization', np.hstack((img, equ)))    # np.hstack 并排显示\n",
    "```\n",
    "> 注意:  \n",
    ">>当直方图中的数据集中在某一个灰度值范围内时，直方图均衡化很有用。但是如果像素的变化很大，而且占据的灰度范围非常广时，例如：既有很亮的像素点又有很暗的像素点时；使用直方图均衡化方式效果并不理想\n",
    "\n",
    "\n",
    "#### 自适应均衡化\n",
    "> 当图像的直方图并不是集中在某一个区域时，需要使用自适应的直方图均衡化。幅图像会被分成很多小块，这些小块被称为“tiles”（在 OpenCV 中 tiles 的大小默认是 8x8），然后再对每一个小块分别进行直方图均衡化（跟前面类似）。所以在每一个的区域中，直方图会集中在某一个小的区域中（除非有噪声干扰）。如果有噪声的话，噪声会被放大。为了避免这种情况的出现要使用对比度限制。对于每个小块来说，如果直方图中的 bin 超过对比度的上限的话，就把其中的像素点均匀分散到其他 bins 中，然后在进行直方图均衡化。最后，为了去除每一个小块之间“人造的”（由于算法造成）边界，再使用双线性差值，对小块进行缝合。\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "createCLAHE([, clipLimit[, tileGridSize]]) -> retval\n",
    "```\n",
    "> 示例:  \n",
    "```python\n",
    "img = cv2.imread('tsukuba_l.png', 0)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "cl1 = clahe.apply(img)\n",
    "cv2.imshow(\"img\", cl1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模板匹配\n",
    "> 模板匹配是一种最原始、最基本的模式识别方法，研究某一特定对象物的图案位于图像的什么地方，进而识别对象物，这就是一个匹配问题。它是图像处理中最基本、最常用的匹配方法。模板匹配具有自身的局限性，主要表现在它只能进行平行移动，若原图像中的匹配目标发生旋转或大小变化，该算法无效。   \n",
    "简单来说，模板匹配就是在整个图像区域发现与给定子图像匹配的小块区域。  \n",
    "工作原理：在带检测图像上，从左到右，从上向下计算模板图像与重叠子图像的匹配度，匹配程度越大，两者相同的可能性越大。\n",
    "\n",
    "### 模板匹配的6种比较方法\n",
    "* 平方差匹配`CV_TM_SQDIFF`：用两者的平方差来匹配，最好的匹配值为0\n",
    "* 归一化平方差匹配`CV_TM_SQDIFF_NORMED`\n",
    "* 相关匹配`CV_TM_CCORR`：用两者的乘积匹配，数值越大表明匹配程度越好\n",
    "* 归一化相关匹配`CV_TM_CCORR_NORMED`\n",
    "* 相关系数匹配`CV_TM_CCOEFF`：用两者的相关系数匹配，1表示完美的匹配，-1表示最差的匹配\n",
    "* 归一化相关系数匹配`CV_TM_CCOEFF_NORMED`  \n",
    "\n",
    "  总结：随着从简单的测量(平方差)到更复杂的测量(相关系数),我们可获得越来越准确的匹配(同时也意味着越来越大的计算代价)。\n",
    "  \n",
    "### [模板匹配函数](https://www.cnblogs.com/FHC1994/p/9123393.html)\n",
    "> 函数原型: (目标匹配)\n",
    "```python\n",
    "matchTemplate(image, templ, method[, result[, mask]]) -> result\n",
    "```\n",
    "> 参数说明:\n",
    "* image 参数表示待搜索源图像，必须是8位整数或32位浮点。\n",
    "* templ 参数表示模板图像，必须不大于源图像并具有相同的数据类型。\n",
    "* method 参数表示计算匹配程度的方法。\n",
    "* result 参数表示匹配结果图像，必须是单通道32位浮点。如果image的尺寸为W\\*H，templ的尺寸为w\\*h，则result的尺寸为(W-w+1)x(H-h+1)\n",
    "\n",
    "> 函数原型: (在给定的矩阵中寻找最大和最小值，并给出它们的位置。该功能不适用于多通道阵列)\n",
    "```python\n",
    "minMaxLoc(src[, mask]) -> minVal, maxVal, minLoc, maxLoc\n",
    "```\n",
    "> 参数说明:\n",
    "* src 参数表示输入单通道图像\n",
    "* mask 参数表示用于选择子数组的可选掩码\n",
    "* minVal 参数表示返回的最小值，如果不需要，则使用NULL\n",
    "* maxVal 参数表示返回的最大值，如果不需要，则使用NULL\n",
    "* minLoc 参数表示返回的最小位置的指针（在2D情况下）; 如果不需要，则使用NULL\n",
    "* maxLoc 参数表示返回的最大位置的指针（在2D情况下）; 如果不需要，则使用NULL\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread(\"lena.jpg\",0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread(\"eye.png\",0)\n",
    "w,h = template.shape[::-1]\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "           'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)    # eval 语句用来计算存储在字符串中的有效 Python 表达式\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "    print meth\n",
    "    plt.subplot(221), plt.imshow(img2,cmap= \"gray\")\n",
    "    plt.title('Original Image'), plt.xticks([]),plt.yticks([])\n",
    "    plt.subplot(222), plt.imshow(template,cmap= \"gray\")\n",
    "    plt.title('template Image'),plt.xticks([]),plt.yticks([])\n",
    "    plt.subplot(223), plt.imshow(res,cmap= \"gray\")\n",
    "    plt.title('Matching Result'), plt.xticks([]),plt.yticks([])\n",
    "    plt.subplot(224), plt.imshow(img,cmap= \"gray\")\n",
    "    plt.title('Detected Point'),plt.xticks([]),plt.yticks([])\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [霍夫变换](https://blog.csdn.net/on2way/article/details/47028969)\n",
    "\n",
    "### 霍夫直线变换\n",
    "> Hough变换的原理是将特定图形上的点变换到一组参数空间上，根据参数空间点的累计结果找到一个极大值对应的解，那么这个解就对应着要寻找的几何形状的参数（比如说直线，那么就会得到直线的斜率k与常熟b，圆就会得到圆心与半径等等）\n",
    "\n",
    "> 一个hough变换在算法设计上就可以如下步骤：\n",
    "1. 将参数空间(ρ,θ)量化，赋初值一个二维矩阵M，M(ρ,θ)就是一个累加器了。 \n",
    "2. 然后对图像边界上的每一个点进行变换，变换到属于哪一组(ρ,θ)，就把该组(ρ,θ)对应的累加器数加1，这里的需要变换的点就是上面说的经过边缘提取以后的图像了。 \n",
    "3. 当所有点处理完成后，就来分析得到的M(ρ,θ)，设置一个阈值T，认为当M(ρ,θ)>T，就认为存在一条有意义的直线存在。而对应的M(ρ,θ)就是这组直线的参数，至于T是多少，自己去式，试的比较合适为止。 \n",
    "4. 有了M(ρ,θ)和点（x,y）计算出来这个直线就ok了。\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "HoughLines(image, rho, theta, threshold[, lines[, srn[, stn[, min_theta[, max_theta]]]]]) -> lines\n",
    "```\n",
    "> 参数说明:\n",
    "* image：要检测的二值图（一般是阈值分割或边缘检测后的图）\n",
    "* rho：距离ρ的精度，值越大，考虑越多的线\n",
    "* theta：角度θ的精度，值越小，考虑越多的线\n",
    "* threshold：累加数阈值，当累加器中的值高于 threshold 时才认为是一条直线\n",
    "\n",
    "> 返回值说明:\n",
    "* 返回一个二维矩阵，表述的就是上述的(ρ,θ)，其中ρ的单位是像素长度（也就是直线到图像原点(0,0)点的距离），而θ的单位是弧度\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('../img/shapes.jpg')\n",
    "drawing = np.zeros(img.shape[:], dtype=np.uint8)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "lines = cv2.HoughLines(edges, 0.8, np.pi/180, 90)\n",
    "print type(lines)   # <type 'numpy.ndarray'>\n",
    "print len(lines)    # 4\n",
    "print lines.shape   # (4L, 1L, 2L)\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(drawing, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "cv2.imshow('line', drawing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "### 统计概率霍夫直线变换\n",
    "> Hough变换会计算图像中的每一个点，计算量比较大，另外它得到的是整一条线（ρ和θ），并不知道原图中直线的端点。所以提出了统计概率霍夫直线变换(Probabilistic Hough Transform, PHT)，是一种改进的霍夫变换\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "HoughLinesP(image, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]]) -> lines\n",
    "```\n",
    "> 参数说明:\n",
    "* image：要检测的二值图（一般是阈值分割或边缘检测后的图）\n",
    "* rho：距离ρ的精度，值越大，考虑越多的线\n",
    "* theta：角度θ的精度，值越小，考虑越多的线\n",
    "* threshold：累加数阈值，当累加器中的值高于 threshold 时才认为是一条直线\n",
    "* minLineLength：最短长度阈值，比这个长度短的线会被排除\n",
    "* maxLineGap：同一直线两点之间的最大距离\n",
    "\n",
    "> 返回值说明:\n",
    "* 返回直线点的坐标位置（这样可以省去一系列for循环中的由参数空间到图像的实际坐标点的转换）\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('../img/shapes.jpg')\n",
    "drawing = np.zeros(img.shape[:], dtype=np.uint8)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "lines = cv2.HoughLinesP(edges, 0.8, np.pi/180, 90, minLineLength=50, maxLineGap=10)\n",
    "print type(lines)   # <type 'numpy.ndarray'>\n",
    "print len(lines)    # 4\n",
    "print lines.shape   # (4L, 1L, 2L)\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(drawing, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "cv2.imshow('line', drawing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "### 霍夫圆变换\n",
    "> 一个圆的确定需要三个参数，那么就需要三层循环来实现（比直线的多一层），从而把图像上的所有点映射到三维参数空间上。其他的就一样了，寻找参数空间累加器的最大（或者大于某一阈值）的值。那么理论上圆的检测将比直线更耗时，然而opencv对其进行了优化，用了一种霍夫梯度法\n",
    "\n",
    "> 函数原型:\n",
    "```python\n",
    "HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) -> circles\n",
    "```\n",
    "> 参数说明:\n",
    "* image：要检测的二值图（一般是阈值分割或边缘检测后的图）\n",
    "* method：变换方法，一般使用霍夫梯度法\n",
    "* dp：dp=1表示霍夫梯度法中累加器图像的分辨率与原图一致\n",
    "* minDist：两个不同圆圆心的最短距离\n",
    "* param2: 跟霍夫直线变换中的累加数阈值一样\n",
    "\n",
    "\n",
    "> 返回值说明:\n",
    "* 返回三个参数（x_center, y_center, r）的空间矩阵\n",
    "\n",
    "> 示例:  \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('../img/shapes.jpg')\n",
    "drawing = np.zeros(img.shape[:], dtype=np.uint8)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20, param2=30)\n",
    "print type(circles)         # <type 'numpy.ndarray'>\n",
    "print circles.ndim          # 3\n",
    "print circles.shape         # (1L, 1L, 3L)\n",
    "circles = np.int0(np.around(circles))\n",
    "for i in circles[0, :]:\n",
    "    cv2.circle(drawing, (i[0], i[1]), i[2], (0, 255, 0), 2)      \n",
    "cv2.imshow('circle', drawing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
